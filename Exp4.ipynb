{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled10.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPofZVGk2e1bVJjMqqZV/xu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/poojakoli63/NNDL_22/blob/main/Exp4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "B6H7I5d9IsV3"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "from tensorflow.keras import layers\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from IPython import display"
      ],
      "metadata": {
        "id": "E9i3MtuUIzXr"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HxJ1T4EIza1",
        "outputId": "02206eb2-7bfa-4e7e-9076-36fcc08921ab"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
        "train_images = (train_images - 127.5) / 127.5  # Normalize the images to [-1, 1]"
      ],
      "metadata": {
        "id": "5BHR3N-jIzfN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_images)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ljva9exvIzis",
        "outputId": "1dea812c-1eff-49f9-9741-c919f6d8b4db"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BUFFER_SIZE = 60000\n",
        "BATCH_SIZE = 256"
      ],
      "metadata": {
        "id": "R6F_8ElbIzph"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch and shuffle the data\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(train_images)\n",
        "train_dataset = train_dataset.shuffle(BUFFER_SIZE)\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE)"
      ],
      "metadata": {
        "id": "a6WpasrYIzsv"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_generator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Reshape((7, 7, 256)))\n",
        "    assert model.output_shape == (None, 7, 7, 256)  # Note: None is the batch size\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 7, 7, 128)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 14, 14, 64)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
        "    assert model.output_shape == (None, 28, 28, 1)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "-FjgUfnhIzvq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = make_generator_model()\n",
        "\n",
        "noise = tf.random.normal([1, 100])\n",
        "generated_image = generator(noise, training=False)\n",
        "\n",
        "plt.imshow(generated_image[0, :, :, 0], cmap='gray')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "mhMYgqf7IzyQ",
        "outputId": "a63ecf37-53f5-4bcc-aed3-a93801403e12"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f5fa2c72890>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generator.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuslcwMMIz1p",
        "outputId": "d9abe4be-cc5b-4097-f4ce-6f5cc3644275"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 12544)             1254400   \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 12544)            50176     \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 12544)             0         \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 7, 7, 256)         0         \n",
            "                                                                 \n",
            " conv2d_transpose (Conv2DTra  (None, 7, 7, 128)        819200    \n",
            " nspose)                                                         \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 7, 7, 128)        512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 7, 7, 128)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_1 (Conv2DT  (None, 14, 14, 64)       204800    \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 14, 14, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " conv2d_transpose_2 (Conv2DT  (None, 28, 28, 1)        1600      \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,330,944\n",
            "Trainable params: 2,305,472\n",
            "Non-trainable params: 25,472\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_discriminator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
        "                                     input_shape=[28, 28, 1]))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(1))\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "CteBZCvzIz4X"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator = make_discriminator_model()\n",
        "decision = discriminator(generated_image)\n",
        "print (decision)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_WpiWuDJPwh",
        "outputId": "1184c522-8104-4a76-8259-efd8c906ed7c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[-0.00088647]], shape=(1, 1), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WM6d0uXdJP7i",
        "outputId": "03e2f4f5-ec2a-49a7-b9fe-be03cdc09a70"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 14, 14, 64)        1664      \n",
            "                                                                 \n",
            " leaky_re_lu_3 (LeakyReLU)   (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 7, 7, 128)         204928    \n",
            "                                                                 \n",
            " leaky_re_lu_4 (LeakyReLU)   (None, 7, 7, 128)         0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 7, 7, 128)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 6272)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 6273      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 212,865\n",
            "Trainable params: 212,865\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This method returns a helper function to compute cross entropy loss\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ],
      "metadata": {
        "id": "SDhnJ5GZJQHJ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss"
      ],
      "metadata": {
        "id": "ohIBjp10JQSO"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
      ],
      "metadata": {
        "id": "oeD7XwWZJQZ4"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
      ],
      "metadata": {
        "id": "sWNTluP5JQiS"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                 discriminator_optimizer=discriminator_optimizer,\n",
        "                                 generator=generator,\n",
        "                                 discriminator=discriminator)"
      ],
      "metadata": {
        "id": "sjFLNe7DJQrF"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 50\n",
        "noise_dim = 100\n",
        "num_examples_to_generate = 16\n",
        "\n",
        "# You will reuse this seed overtime (so it's easier)\n",
        "# to visualize progress in the animated GIF)\n",
        "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
      ],
      "metadata": {
        "id": "aru3mzoXJQym"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Notice the use of `tf.function`\n",
        "# This annotation causes the function to be \"compiled\".\n",
        "@tf.function\n",
        "def train_step(images):\n",
        "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      generated_images = generator(noise, training=True)\n",
        "\n",
        "      real_output = discriminator(images, training=True)\n",
        "      fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "      gen_loss = generator_loss(fake_output)\n",
        "      disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
      ],
      "metadata": {
        "id": "afZH_ROwJQ7q"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataset, epochs):\n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "\n",
        "    for image_batch in dataset:\n",
        "      train_step(image_batch)\n",
        "\n",
        "    # Produce images for the GIF as you go\n",
        "    display.clear_output(wait=True)\n",
        "    generate_and_save_images(generator,\n",
        "                             epoch + 1,\n",
        "                             seed)\n",
        "\n",
        "    # Save the model every 15 epochs\n",
        "    if (epoch + 1) % 15 == 0:\n",
        "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
        "\n",
        "  # Generate after the final epoch\n",
        "  display.clear_output(wait=True)\n",
        "  generate_and_save_images(generator,\n",
        "                           epochs,\n",
        "                           seed)"
      ],
      "metadata": {
        "id": "n2zDK4dIJRKx"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_and_save_images(model, epoch, test_input):\n",
        "  # Notice `training` is set to False.\n",
        "  # This is so all layers run in inference mode (batchnorm).\n",
        "  predictions = model(test_input, training=False)\n",
        "\n",
        "  fig = plt.figure(figsize=(4, 4))\n",
        "\n",
        "  for i in range(predictions.shape[0]):\n",
        "      plt.subplot(4, 4, i+1)\n",
        "      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
        "      plt.axis('off')\n",
        "\n",
        "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "P9b93ztmJxq7"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(train_dataset, EPOCHS)"
      ],
      "metadata": {
        "id": "iCdIg9pmJyEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7MJbc70JyTY",
        "outputId": "368c4b27-6479-4093-d114-14ada72a5c38"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.InitializationOnlyStatus at 0x7f5fa2751a50>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "eL3L0nG4JRm_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}